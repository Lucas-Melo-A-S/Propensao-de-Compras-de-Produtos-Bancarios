# Uma compara√ß√£o entre modelos balanceados e desbalanceados (Bank Marketing)

Este reposit√≥rio cont√©m um estudo aplicado ao dataset **Bank Marketing** (Kaggle/UCI) para comparar o comportamento de modelos de classifica√ß√£o em **dois cen√°rios**:

1) **Dados desbalanceados** (realidade bruta do problema)  
2) **Dados balanceados via undersampling** (igualando a classe majorit√°ria √† minorit√°ria)

O foco √© entender o impacto do desbalanceamento em m√©tricas cr√≠ticas para neg√≥cio (especialmente **Recall**), j√° que em campanhas de marketing/CRM **falsos negativos** representam oportunidade perdida de convers√£o.

---

## üéØ Problema

Prever a vari√°vel-alvo **`y`**:
- `yes`: cliente aderiu ao dep√≥sito a prazo (evento raro)
- `no`: cliente n√£o aderiu (maioria)

Em bases altamente desbalanceadas, muitos modelos tendem a ‚Äúaprender o caminho f√°cil‚Äù e prever sempre a classe majorit√°ria, o que gera:
- **Recall baixo**
- Muitos **falsos negativos**
- Campanhas menos eficientes (mais contatos desperdi√ßados / menos convers√£o)

---

## üìå Dataset

- **Nome:** Bank Marketing (bank-additional-full.csv)
- **Tamanho:** ~41.188 linhas, 20 atributos (2008‚Äì2010)
- **Origem:** Kaggle (dataset popular de campanhas telef√¥nicas)

### Observa√ß√µes importantes do dataset (tratamentos aplicados)
- `duration` √© altamente correlacionada com `y`, mas **n√£o estaria dispon√≠vel antes da liga√ß√£o** ‚Üí **removida** para evitar leakage.
- `pdays = 999` indica ‚Äúnunca contatado‚Äù ‚Üí convertido para `NaN`; como gerou grande volume de aus√™ncias, a feature foi **exclu√≠da**.
- Registros com categorias `unknown` em features categ√≥ricas foram **removidos**.
- Features categ√≥ricas de **baixa cardinalidade (< 30)** foram transformadas via **OneHotEncoder**.
- Vari√°veis num√©ricas foram padronizadas com **StandardScaler**.

---

## üß± Pipeline (vis√£o geral)

1. **Train/Test Split** (antes de qualquer tratamento para reduzir risco de leakage)
2. Limpeza e regras de neg√≥cio:
   - remover `duration`
   - tratar `pdays`
   - remover linhas com `unknown`
3. **Encoding**:
   - OneHotEncoder para categ√≥ricas (baixa cardinalidade)
4. **Scaling**:
   - StandardScaler para num√©ricas
5. **Feature Selection**:
   - **Random Forest Feature Importance** com cutoff de **20%**
6. Modelagem em dois cen√°rios:
   - **Desbalanceado**
   - **Balanceado (undersampling)**

---

## ü§ñ Modelos avaliados

- **Decision Tree**
- **Random Forest**
- **XGBoost**

### M√©tricas utilizadas
- ROC AUC
- Gini
- KS
- Precision
- Recall
- F1-score
- Confusion Matrix
- Curvas ROC e Precision‚ÄìRecall
- Ordena√ß√£o por score (ranking/decis)

---

## üß™ Resultados (highlights)

### üîª Cen√°rio 1 ‚Äî Dados desbalanceados
Apesar de m√©tricas globais ‚Äúboas‚Äù (AUC ~0.79‚Äì0.80), os modelos apresentaram **Recall extremamente baixo (~17%)**, com muitos falsos negativos:

- **Decision Tree**: Recall ~0.17  
- **Random Forest**: Recall ~0.16  
- **XGBoost**: Recall ~0.17  

**Interpreta√ß√£o pr√°tica:** o modelo parece bom pela AUC, mas falha em identificar quem realmente tem chance de aderir ‚Äî ruim para prioriza√ß√£o de leads.

---

### üî∫ Cen√°rio 2 ‚Äî Dados balanceados (undersampling)
O balanceamento alterou o comportamento estrutural dos modelos e aumentou muito a capacidade de detectar a classe positiva:

- **Decision Tree**: Recall **0.676**
- **Random Forest**: Recall **0.684**
- **XGBoost**: Recall **0.705** (com Precision **0.815** e F1 **0.756**)

**Destaque:** o **XGBoost balanceado** foi o melhor equil√≠brio entre Recall, Precision, F1 e estabilidade (m√©tricas e curvas coerentes entre treino e teste).

> Principal li√ß√£o: n√£o basta ‚Äúescolher o melhor modelo‚Äù.  
> Em eventos raros, **dar condi√ß√µes para o modelo aprender** (balanceamento/weights/SMOTE) √© uma decis√£o estrat√©gica.

---

## üìÅ Arquivos do projeto

- `Propens√£o de Compras de Produtos Banc√°rios.ipynb`  
  Notebook principal com:
  - prepara√ß√£o dos dados
  - feature selection
  - treino e avalia√ß√£o (desbalanceado vs balanceado)
  - visualiza√ß√µes e m√©tricas

> Observa√ß√£o: o notebook atualmente referencia caminhos do Google Drive (Colab). Veja abaixo como adaptar.

---
